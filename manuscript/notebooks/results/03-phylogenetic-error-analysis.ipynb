{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c0e5bf",
   "metadata": {},
   "source": [
    "## Phylogenetic error assessment\n",
    "\n",
    "We analyzed prediction errors across 102 genera to test whether model performance was systematically structured by phylogeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import sys\n",
    "from typing import Union, List, Dict, Any, Optional\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paths\n",
    "PROJECT_DIR = Path.cwd().parent.parent.parent\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "from anglecam import AngleCam\n",
    "\n",
    "IMAGES_DIR = PROJECT_DIR / \"data\" / \"01_Training_Validation_Data\" / \"image_data\"\n",
    "DATA_PATH = PROJECT_DIR / \"data\" / \"01_Training_Validation_Data\" / \"splits\"\n",
    "\n",
    "PHYLO_RESULTS_PATH = PROJECT_DIR / \"data\" / \"03_Model_Outputs\" / \"predictions\" / \"phylogenetic_error_assesment\"\n",
    "FIGURES_PATH = PROJECT_DIR / \"data\" / \"other\" / \"figures\" / \"results\" \n",
    "\n",
    "OUTPUT_DIR = PROJECT_DIR / \"data\" / \"03_Model_Outputs\" / \"checkpoint\"\n",
    "CHECKPOINT_PATH = OUTPUT_DIR / \"AngleCamV2.pth\"\n",
    "\n",
    "assert CHECKPOINT_PATH.exists(), f\"Checkpoint path not found: {CHECKPOINT_PATH}\"\n",
    "assert DATA_PATH.exists(), f\"Data path not found: {DATA_PATH}\"\n",
    "assert PHYLO_RESULTS_PATH.exists(), f\"Phylogenetic results path not found: {PHYLO_RESULTS_PATH}\"\n",
    "assert FIGURES_PATH.exists(), f\"Figures path not found: {FIGURES_PATH}\"\n",
    "assert OUTPUT_DIR.exists(), f\"Output directory not found: {OUTPUT_DIR}\"\n",
    "assert IMAGES_DIR.exists(), f\"Images directory not found: {IMAGES_DIR}\"\n",
    "\n",
    "# Load data\n",
    "phylo_data = pd.read_csv(DATA_PATH / \"phylo.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f723cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "config_overrides = {\n",
    "    \"training\": {\n",
    "        \"output_dir\": \"data/model/output\" \n",
    "    }\n",
    "}\n",
    "\n",
    "anglecam = AngleCam.from_checkpoint(\n",
    "    str(CHECKPOINT_PATH), \n",
    "    config_overrides=config_overrides\n",
    ")\n",
    "anglecam.device = device\n",
    "\n",
    "# Move model to selected device for later inference\n",
    "anglecam.model.to(device)\n",
    "\n",
    "print(\"Model loaded and ready for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a566a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(\n",
    "    model,\n",
    "    input_data: Union[str, Path, pd.DataFrame],\n",
    "    images_dir: Path,\n",
    "    output_path: Optional[Path] = None,\n",
    "    batch_size: int = 128,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Batch prediction function.\n",
    "\n",
    "    Args:\n",
    "        model: AngleCam model instance with predict() method\n",
    "        input_data: Either a CSV file path/DataFrame with 'filename' column, or single image path\n",
    "        images_dir: Directory where images are stored (IMAGES_DIR)\n",
    "        output_path: Optional path to save results as JSON\n",
    "        batch_size: Number of images to process before clearing GPU cache (default: 128)\n",
    "\n",
    "    Returns:\n",
    "        List of prediction results\n",
    "    \"\"\"\n",
    "\n",
    "    def load_labels_robust(labels_filepath: Path) -> tuple:\n",
    "        \"\"\"Load labels with automatic separator detection.\"\"\"\n",
    "        try:\n",
    "            # First try with space separator\n",
    "            labels_df = pd.read_csv(labels_filepath, sep=\" \", header=None)\n",
    "            labels = labels_df.iloc[0, :].to_numpy(dtype=float)\n",
    "        except (ValueError, TypeError):\n",
    "            try:\n",
    "                # If space fails, try comma separator\n",
    "                labels_df = pd.read_csv(labels_filepath, sep=\",\", header=None)\n",
    "                labels = labels_df.iloc[0, :].to_numpy(dtype=float)\n",
    "            except (ValueError, TypeError):\n",
    "                try:\n",
    "                    # Try automatic separator detection\n",
    "                    labels_df = pd.read_csv(labels_filepath, header=None)\n",
    "                    labels = labels_df.iloc[0, :].to_numpy(dtype=float)\n",
    "                except Exception as e:\n",
    "                    raise ValueError(\n",
    "                        f\"Could not parse labels file with any separator: {e}\"\n",
    "                    )\n",
    "\n",
    "        # Normalize and calculate mean\n",
    "        labels = labels / labels.sum()\n",
    "        labels_mean = np.sum(np.linspace(0, 90, 43) * labels)\n",
    "        return labels_mean, labels.tolist()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Handle input data and create lookup for genus/species\n",
    "    genus_species_lookup = {}\n",
    "    if isinstance(input_data, (str, Path)):\n",
    "        input_path = Path(input_data)\n",
    "        if input_path.suffix == \".csv\":\n",
    "            df = pd.read_csv(input_path)\n",
    "            filenames = df[\"filename\"].tolist()\n",
    "            # Create lookup dictionary for genus and species\n",
    "            if \"Genus\" in df.columns and \"species\" in df.columns:\n",
    "                for _, row in df.iterrows():\n",
    "                    genus_species_lookup[row[\"filename\"]] = {\n",
    "                        \"genus\": row[\"Genus\"],\n",
    "                        \"species\": row[\"species\"]\n",
    "                    }\n",
    "        else:\n",
    "            filenames = [input_path.name]\n",
    "    elif isinstance(input_data, pd.DataFrame):\n",
    "        df = input_data\n",
    "        filenames = df[\"filename\"].tolist()\n",
    "        # Create lookup dictionary for genus and species\n",
    "        if \"Genus\" in df.columns and \"species\" in df.columns:\n",
    "            for _, row in df.iterrows():\n",
    "                genus_species_lookup[row[\"filename\"]] = {\n",
    "                    \"genus\": row[\"Genus\"],\n",
    "                    \"species\": row[\"species\"]\n",
    "                }\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported input type: {type(input_data)}\")\n",
    "\n",
    "    print(f\"Processing {len(filenames)} images in batches of {batch_size}\")\n",
    "\n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(filenames), batch_size), desc=\"Processing batches\"):\n",
    "        batch_filenames = filenames[i : i + batch_size]\n",
    "\n",
    "        for filename in batch_filenames:\n",
    "            try:\n",
    "                # Image filepath\n",
    "                image_filepath = images_dir / filename\n",
    "\n",
    "                if not image_filepath.exists():\n",
    "                    print(f\"Warning: Image not found: {image_filepath}\")\n",
    "                    results.append(\n",
    "                        {\"filename\": filename, \"error\": \"Image file not found\"}\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Get genus and species from lookup\n",
    "                genus = genus_species_lookup.get(filename, {}).get(\"genus\", \"Unknown\")\n",
    "                species = genus_species_lookup.get(filename, {}).get(\"species\", \"Unknown\")\n",
    "\n",
    "                # Check if labels exist\n",
    "                labels_filepath = images_dir / (filename.split(\".\")[0] + \"_sim.csv\")\n",
    "                sim_data = {\"distribution\": None, \"mean_angle\": None}\n",
    "\n",
    "                if labels_filepath.exists():\n",
    "                    try:\n",
    "                        labels_mean, labels_distribution = load_labels_robust(\n",
    "                            labels_filepath\n",
    "                        )\n",
    "                        sim_data = {\n",
    "                            \"distribution\": labels_distribution,\n",
    "                            \"mean_angle\": labels_mean\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not load labels for {filename}: {e}\")\n",
    "\n",
    "                # Predict the angle\n",
    "                pred_result = model.predict(image_filepath)\n",
    "                \n",
    "                # Structure prediction data\n",
    "                pred_data = {\n",
    "                    \"distribution\": pred_result[\"angle_distribution\"],\n",
    "                    \"mean_angle\": pred_result[\"predicted_mean_leaf_angle\"]\n",
    "                }\n",
    "\n",
    "                # Create result dictionary in the new format\n",
    "                result = {\n",
    "                    \"filename\": filename,\n",
    "                    \"genus\": genus,\n",
    "                    \"species\": species,\n",
    "                    \"predicted_distribution\": pred_data['distribution'],\n",
    "                    \"predicted_mean_angle\": pred_data['mean_angle'],\n",
    "                    \"reference_distribution\": sim_data['distribution'],\n",
    "                    \"reference_mean_angle\": sim_data['mean_angle'],\n",
    "                }\n",
    "\n",
    "                results.append(result)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                error_result = {\"filename\": filename, \"error\": str(e)}\n",
    "                results.append(error_result)\n",
    "\n",
    "        # Clear GPU cache between batches to manage memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Save results if output path provided\n",
    "    if output_path:\n",
    "        output_path = Path(output_path)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"Results saved to {output_path}\")\n",
    "\n",
    "    print(f\"Completed processing {len(results)} images\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# results = batch_predict(anglecam, training_data, IMAGES_DIR, output_path=\"results.json\")\n",
    "# results = batch_predict(anglecam, \"path/to/filenames.csv\", IMAGES_DIR)\n",
    "# results = batch_predict(anglecam, single_image_path, IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predict(anglecam, phylo_data, IMAGES_DIR, output_path=PHYLO_RESULTS_PATH / \"phylogenetic_error_results_anglecam_v2_raw.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696d8f8",
   "metadata": {},
   "source": [
    "### Create csv file containing the prediction errors per genus\n",
    "\n",
    "Further processing will be done in R\n",
    "\n",
    "Steps:\n",
    "- Generate tree\n",
    "- Match prediction error to tree\n",
    "- Calculate Pagel's lambda\n",
    "- Calculate Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57db0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_genus_csv(json_file_path: str, output_csv_path: str) -> pd.DataFrame:\n",
    "    # Load JSON results\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    # Group results by genus\n",
    "    genus_groups = defaultdict(list)\n",
    "\n",
    "    for result in results:\n",
    "        genus = result.get(\"genus\", None)\n",
    "        # Skip if genus is missing or invalid\n",
    "        if genus and genus not in [None, \"nan\", \"\", \"None\"]:\n",
    "            # Calculate absolute error\n",
    "            predicted_angle = result.get(\"predicted_mean_angle\", 0)\n",
    "            reference_angle = result.get(\"reference_mean_angle\", 0)\n",
    "            abs_error = abs(predicted_angle - reference_angle)\n",
    "\n",
    "            genus_groups[genus].append(abs_error)\n",
    "\n",
    "    # Calculate statistics for each genus\n",
    "    genus_stats = []\n",
    "    for genus, errors in genus_groups.items():\n",
    "        genus_stats.append(\n",
    "            {\n",
    "                \"genus\": genus,\n",
    "                \"mean_abs_error\": np.mean(errors),\n",
    "                \"sample_size\": len(errors),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Create DataFrame and sort by genus name\n",
    "    df = pd.DataFrame(genus_stats)\n",
    "    df = df.sort_values(\"genus\").reset_index(drop=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Genus-level statistics saved to: {output_csv_path}\")\n",
    "    print(f\"Summary: {len(df)} genera, {df['sample_size'].sum()} total samples\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Version with additional statistics\n",
    "def json_to_genus_csv_extended(\n",
    "    json_file_path: str, output_csv_path: str\n",
    ") -> pd.DataFrame:\n",
    "    # Load JSON results\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    # Group results by genus\n",
    "    genus_groups = defaultdict(list)\n",
    "\n",
    "    for result in results:\n",
    "        genus = result.get(\"genus\", None)\n",
    "        # Skip if genus is missing or invalid\n",
    "        if genus and genus not in [None, \"nan\", \"\", \"None\"]:\n",
    "            predicted_angle = result.get(\"predicted_mean_angle\", 0)\n",
    "            reference_angle = result.get(\"reference_mean_angle\", 0)\n",
    "\n",
    "            genus_groups[genus].append(\n",
    "                {\n",
    "                    \"predicted\": predicted_angle,\n",
    "                    \"reference\": reference_angle,\n",
    "                    \"abs_error\": abs(predicted_angle - reference_angle),\n",
    "                    \"error\": predicted_angle - reference_angle,\n",
    "                    \"species\": result.get(\"species\", \"\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Calculate statistics for each genus\n",
    "    genus_stats = []\n",
    "    for genus, data in genus_groups.items():\n",
    "        abs_errors = [d[\"abs_error\"] for d in data]\n",
    "        errors = [d[\"error\"] for d in data]\n",
    "        predicted_angles = [d[\"predicted\"] for d in data]\n",
    "        reference_angles = [d[\"reference\"] for d in data]\n",
    "        species_set = set(d[\"species\"] for d in data if d[\"species\"])\n",
    "\n",
    "        genus_stats.append(\n",
    "            {\n",
    "                \"genus\": genus,\n",
    "                \"mean_abs_error\": np.mean(abs_errors),\n",
    "                \"sample_size\": len(data),\n",
    "                \"std_abs_error\": np.std(abs_errors),\n",
    "                \"rmse\": np.sqrt(np.mean([e**2 for e in errors])),\n",
    "                \"bias\": np.mean(errors),\n",
    "                \"mean_predicted_angle\": np.mean(predicted_angles),\n",
    "                \"mean_reference_angle\": np.mean(reference_angles),\n",
    "                \"species_count\": len(species_set),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Create DataFrame and sort by mean absolute error\n",
    "    df = pd.DataFrame(genus_stats)\n",
    "    df = df.sort_values(\"mean_abs_error\").reset_index(drop=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Genus-level statistics saved to: {output_csv_path}\")\n",
    "    print(f\"Summary: {len(df)} genera, {df['sample_size'].sum()} total samples\")\n",
    "\n",
    "    # Print top and bottom performers\n",
    "    print(f\"\\nBest performing genera (lowest MAE):\")\n",
    "    print(df.head(3)[[\"genus\", \"mean_abs_error\", \"sample_size\"]].to_string(index=False))\n",
    "    print(f\"\\nWorst performing genera (highest MAE):\")\n",
    "    print(df.tail(3)[[\"genus\", \"mean_abs_error\", \"sample_size\"]].to_string(index=False))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Simple usage function\n",
    "def create_genus_summary_csv(json_path: str, csv_path: str = None) -> pd.DataFrame:\n",
    "    if csv_path is None:\n",
    "        csv_path = json_path.replace(\".json\", \"_genus_summary.csv\")\n",
    "\n",
    "    return json_to_genus_csv(json_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = PHYLO_RESULTS_PATH / \"phylogenetic_error_results_anglecam_v2_raw.json\"\n",
    "output_file = PHYLO_RESULTS_PATH / \"phylogenetic_error_results_anglecam_v2_genus_statistics.csv\"\n",
    "\n",
    "phylo_results = json_to_genus_csv_extended(json_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "phylo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distribution statistics for mean absolute errors\n",
    "# Calculate percentiles and summary statistics\n",
    "mae_values = phylo_results['mean_abs_error']\n",
    "\n",
    "# Basic statistics\n",
    "min_mae = mae_values.min()\n",
    "max_mae = mae_values.max()\n",
    "median_mae = mae_values.median()\n",
    "mean_mae = mae_values.mean()\n",
    "\n",
    "# Quartiles\n",
    "q25 = mae_values.quantile(0.25)\n",
    "q75 = mae_values.quantile(0.75)\n",
    "iqr = q75 - q25\n",
    "\n",
    "# Additional percentiles\n",
    "q10 = mae_values.quantile(0.10)\n",
    "q90 = mae_values.quantile(0.90)\n",
    "\n",
    "print(\"Mean Absolute Error Distribution Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Range: {min_mae:.2f}° to {max_mae:.2f}°\")\n",
    "print(f\"Mean: {mean_mae:.2f}°\")\n",
    "print(f\"Median: {median_mae:.2f}°\")\n",
    "print(f\"Standard deviation: {mae_values.std():.2f}°\")\n",
    "print()\n",
    "print(\"Percentiles:\")\n",
    "print(f\"10th percentile: {q10:.2f}°\")\n",
    "print(f\"25th percentile (Q1): {q25:.2f}°\")\n",
    "print(f\"50th percentile (Median): {median_mae:.2f}°\")\n",
    "print(f\"75th percentile (Q3): {q75:.2f}°\")\n",
    "print(f\"90th percentile: {q90:.2f}°\")\n",
    "print()\n",
    "print(f\"Interquartile range (IQR): {q25:.1f}° to {q75:.1f}°\")\n",
    "print(f\"IQR span: {iqr:.2f}°\")\n",
    "print()\n",
    "\n",
    "# Count genera in different ranges\n",
    "count_1_5 = len(mae_values[(mae_values >= 1) & (mae_values <= 5)])\n",
    "count_5_10 = len(mae_values[(mae_values > 5) & (mae_values <= 10)])\n",
    "count_5_11 = len(mae_values[(mae_values > 5) & (mae_values <= 11)])\n",
    "count_5_12 = len(mae_values[(mae_values > 5) & (mae_values <= 12)])\n",
    "count_10_plus = len(mae_values[mae_values > 10])\n",
    "\n",
    "total_genera = len(mae_values)\n",
    "\n",
    "print(\"Distribution across ranges:\")\n",
    "print(f\"1-5°: {count_1_5} genera ({count_1_5/total_genera*100:.1f}%)\")\n",
    "print(f\"5-10°: {count_5_10} genera ({count_5_10/total_genera*100:.1f}%)\")\n",
    "print(f\"5-11°: {count_5_11} genera ({count_5_11/total_genera*100:.1f}%)\")\n",
    "print(f\"5-12°: {count_5_12} genera ({count_5_12/total_genera*100:.1f}%)\")\n",
    "print(f\">10°: {count_10_plus} genera ({count_10_plus/total_genera*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean absolute errors ranged from {min_mae:.0f}° to {max_mae:.0f}°, \")\n",
    "print(f\"with the majority of genera falling between {q25:.0f}° and {q75:.0f}°\")\n",
    "print(f\"(interquartile range, covering {count_5_11} of {total_genera} genera, {count_5_11/total_genera*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d24b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(mae_values, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(median_mae, color='red', linestyle='--', label=f'Median: {median_mae:.1f}°')\n",
    "plt.axvline(q25, color='orange', linestyle='--', label=f'Q1: {q25:.1f}°')\n",
    "plt.axvline(q75, color='orange', linestyle='--', label=f'Q3: {q75:.1f}°')\n",
    "plt.xlabel('Mean Absolute Error (degrees)')\n",
    "plt.ylabel('Number of Genera')\n",
    "plt.title('Distribution of Mean Absolute Errors')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(1, 2, 2)\n",
    "box_plot = plt.boxplot(mae_values, vert=True, patch_artist=True)\n",
    "box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "plt.ylabel('Mean Absolute Error (degrees)')\n",
    "plt.title('Box Plot of Mean Absolute Errors')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text annotations on box plot\n",
    "plt.text(1.1, median_mae, f'Median: {median_mae:.1f}°', va='center')\n",
    "plt.text(1.1, q25, f'Q1: {q25:.1f}°', va='center')\n",
    "plt.text(1.1, q75, f'Q3: {q75:.1f}°', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table of best and worst performers\n",
    "print(\"\\nBest performing genera (lowest MAE):\")\n",
    "print(phylo_results.head(5)[['genus', 'mean_abs_error', 'sample_size']].to_string(index=False))\n",
    "\n",
    "print(\"\\nWorst performing genera (highest MAE):\")\n",
    "print(phylo_results.tail(5)[['genus', 'mean_abs_error', 'sample_size']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anglecam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
