{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c75228",
   "metadata": {},
   "source": [
    "# Animation of the testing results with TLS as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ebb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and path setup\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "# Ensure project root is on sys.path for imports if needed\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent.parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Paths\n",
    "TESTING_CSV = PROJECT_ROOT / \"data\" / \"01_Training_Validation_Data\" / \"splits\" / \"testing.csv\"\n",
    "IMAGES_DIR = PROJECT_ROOT / \"data\" / \"01_Training_Validation_Data\" / \"image_data\"\n",
    "TLS_DIR = PROJECT_ROOT / \"data\" / \"02_Test_Data\" / \"TLS\" / \"analysis\"\n",
    "#TESTING_DIR_CALATHEA = PROJECT_ROOT / \"data/02_Test_Data/images/calathea_ornata\"\n",
    "#TESTING_DIR_MARANTA = PROJECT_ROOT / \"data/02_Test_Data/images/maranta_leuconeura\"\n",
    "TESTING_DIR_CALATHEA = PROJECT_ROOT / \"data/other/images/testing/calathea_ornata_all_images\"\n",
    "TESTING_DIR_MARANTA = PROJECT_ROOT / \"data/other/images/testing/maranta_leuconeura_all_images\"\n",
    "\n",
    "TESTING_RESULTS_DIR = PROJECT_ROOT / \"data\" / \"03_Model_Outputs\" / \"predictions\" / \"testing\"\n",
    "FIGURE_OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"other\" / \"figures\" / \"results\"\n",
    "ANIMATION_OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"04_Supplementary_Material\"\n",
    "\n",
    "# Colors\n",
    "custom_colors = [\"#C2B2B4\", \"#6B4E71\", \"#3A4454\", \"#53687E\", \"#F5DDDD\"]\n",
    "custom_colors2 = [\"#F1F1FE\", \"#9492B9\", \"#AFBFCD\", \"#3A739D\", \"#ADC0A8\"]\n",
    "\n",
    "# Create color palette\n",
    "custom_palette = sns.color_palette(custom_colors)\n",
    "custom_palette2 = sns.color_palette(custom_colors2)\n",
    "\n",
    "# Basic checks\n",
    "assert TESTING_CSV.exists(), f\"Testing CSV not found: {TESTING_CSV}\"\n",
    "assert IMAGES_DIR.exists(), f\"Images directory not found: {IMAGES_DIR}\"\n",
    "assert TLS_DIR.exists(), f\"TLS directory not found: {TLS_DIR}\"\n",
    "assert TESTING_DIR_CALATHEA.exists(), f\"Calathea testing directory not found: {TESTING_DIR_CALATHEA}\"\n",
    "assert TESTING_DIR_MARANTA.exists(), f\"Maranta testing directory not found: {TESTING_DIR_MARANTA}\"\n",
    "assert TESTING_RESULTS_DIR.exists(), f\"Testing results directory not found: {TESTING_RESULTS_DIR}\"\n",
    "assert FIGURE_OUTPUT_DIR.exists(), f\"Figure output directory not found: {FIGURE_OUTPUT_DIR}\"\n",
    "assert ANIMATION_OUTPUT_DIR.exists(), f\"Animation output directory not found: {ANIMATION_OUTPUT_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TESTING_RESULTS_DIR / \"calathea_ornata_predictions.json\", \"r\") as f:\n",
    "    calathea_results = json.load(f)\n",
    "\n",
    "with open(TESTING_RESULTS_DIR / \"maranta_leuconeura_predictions.json\", \"r\") as f:\n",
    "    maranta_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animation parameters - centralized configuration\n",
    "ANIMATION_CONFIG = {\n",
    "    'target_duration_seconds': 20,  # Changed to 20 seconds\n",
    "    'dpi': 120,  # Reduced for faster processing\n",
    "    'figure_size': (18, 7),  # Slightly smaller for speed\n",
    "    'width_ratios': [1.5, 1],  # Time series : Image ratio\n",
    "    'subplot_spacing': 0.02,\n",
    "    \n",
    "    # Visual parameters\n",
    "    'rolling_window': 3,\n",
    "    'marker_size': 60,  # Slightly smaller\n",
    "    'line_width': 4,\n",
    "    'alpha_scatter': 0.7,\n",
    "    'alpha_grid': 0.2,\n",
    "    \n",
    "    # Font sizes\n",
    "    'xlabel_fontsize': 14,\n",
    "    'ylabel_fontsize': 14,\n",
    "    'legend_fontsize': 12,\n",
    "    'tick_labelsize': 12,\n",
    "    'title_fontsize': 16,\n",
    "    \n",
    "    # Colors\n",
    "    'anglecam_color': custom_palette2[3],\n",
    "    'tls_color': custom_palette[1],\n",
    "    'night_color': '#f0f0f0',\n",
    "    'night_alpha': 1.0,\n",
    "    \n",
    "    # Day/night timing\n",
    "    'day_start_hour': 8,\n",
    "    'day_end_hour': 18,\n",
    "    \n",
    "    # GIF-specific parameters\n",
    "    'gif_duration_ms': 1,  # Duration between frames in milliseconds\n",
    "    'gif_optimize': True,  # Optimize GIF for smaller file size\n",
    "    'gif_loop': 0,  # Loop forever (0 = infinite loop)\n",
    "    'gif_max_colors': 256,  # Maximum colors in GIF palette\n",
    "}\n",
    "\n",
    "def extract_datetime_from_filename(filename):\n",
    "    \"\"\"Extract datetime from image filename.\"\"\"\n",
    "    # G5Bullet_55_2025-01-17_17_32_00_corrected.jpg\n",
    "    parts = filename.split('_')\n",
    "    date_part = parts[2]  # 2025-01-17\n",
    "    hour_part = parts[3]  # 17\n",
    "    minute_part = parts[4]  # 32\n",
    "    \n",
    "    # Parse datetime\n",
    "    year, month, day = date_part.split('-')\n",
    "    datetime_str = f\"{day}-{month}-{year} {hour_part}:{minute_part}\"\n",
    "    return datetime.strptime(datetime_str, \"%d-%m-%Y %H:%M\")\n",
    "\n",
    "def get_all_image_files(image_dir):\n",
    "    \"\"\"Get all image files sorted by datetime.\"\"\"\n",
    "    image_files = []\n",
    "    for img_path in Path(image_dir).glob(\"*.jpg\"):\n",
    "        try:\n",
    "            dt = extract_datetime_from_filename(img_path.name)\n",
    "            image_files.append((dt, img_path))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Sort by datetime\n",
    "    image_files.sort(key=lambda x: x[0])\n",
    "    return image_files\n",
    "\n",
    "def prepare_prediction_data(results):\n",
    "    \"\"\"Prepare prediction data with timestamps and pre-calculate smoothed lines.\"\"\"\n",
    "    data = []\n",
    "    for result in results['predictions']: \n",
    "        try:\n",
    "            dt = datetime.strptime(result['datetime'], \"%d-%m-%Y %H:%M\")\n",
    "            data.append({\n",
    "                'filename': result['filename'],\n",
    "                'predicted_mean_angle': result['predicted_mean_angle'],\n",
    "                'reference_mean_angle': result['reference_mean_angle'],\n",
    "                'timestamp': dt\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    df = pd.DataFrame(data).sort_values('timestamp')\n",
    "    \n",
    "    # Pre-calculate smoothed lines for ALL data\n",
    "    if len(df) > 0:\n",
    "        df['reference_smooth'] = (\n",
    "            df['reference_mean_angle']\n",
    "            .rolling(window=ANIMATION_CONFIG['rolling_window'], center=True, min_periods=1)\n",
    "            .mean()\n",
    "        )\n",
    "        df['predicted_smooth'] = (\n",
    "            df['predicted_mean_angle']\n",
    "            .rolling(window=ANIMATION_CONFIG['rolling_window'], center=True, min_periods=1)\n",
    "            .mean()\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_animation_frame_optimized(args):\n",
    "    \"\"\"Optimized frame creation function for multiprocessing.\"\"\"\n",
    "    frame_idx, image_files, prediction_data_full, output_path, config, plant_name, time_range, y_range = args\n",
    "    \n",
    "    # Get current image\n",
    "    current_dt, current_image_path = image_files[frame_idx]\n",
    "    \n",
    "    # Get predictions up to current time (using pre-calculated smoothed data)\n",
    "    current_predictions = prediction_data_full[prediction_data_full['timestamp'] <= current_dt].copy()\n",
    "    \n",
    "    # Create figure with optimized settings\n",
    "    plt.ioff()  # Turn off interactive mode for speed\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        1, 2, \n",
    "        figsize=config['figure_size'],\n",
    "        gridspec_kw={\"width_ratios\": config['width_ratios'], \"wspace\": config['subplot_spacing']},\n",
    "        dpi=config['dpi']\n",
    "    )\n",
    "    \n",
    "    # LEFT PLOT: Time series (evolving)\n",
    "    time_min, time_max = time_range\n",
    "    y_min, y_max = y_range\n",
    "    \n",
    "    # Add day/night background (pre-calculated)\n",
    "    dates = pd.date_range(time_min.date(), time_max.date(), freq='D').date\n",
    "    \n",
    "    for date in dates:\n",
    "        # Night periods\n",
    "        night_start_early = pd.Timestamp.combine(date, time(0, 0))\n",
    "        night_end_early = pd.Timestamp.combine(date, time(config['day_start_hour'], 0))\n",
    "        night_start_late = pd.Timestamp.combine(date, time(config['day_end_hour'], 0))\n",
    "        night_end_late = pd.Timestamp.combine(date, time(23, 59, 59))\n",
    "        \n",
    "        # Shade night periods\n",
    "        if night_end_early >= time_min and night_start_early <= time_max:\n",
    "            ax1.axvspan(\n",
    "                max(night_start_early, time_min), \n",
    "                min(night_end_early, time_max),\n",
    "                color=config['night_color'], \n",
    "                alpha=config['night_alpha'], \n",
    "                zorder=0\n",
    "            )\n",
    "        \n",
    "        if night_end_late >= time_min and night_start_late <= time_max:\n",
    "            ax1.axvspan(\n",
    "                max(night_start_late, time_min), \n",
    "                min(night_end_late, time_max),\n",
    "                color=config['night_color'], \n",
    "                alpha=config['night_alpha'], \n",
    "                zorder=0\n",
    "            )\n",
    "    \n",
    "    # Plot data if available\n",
    "    if len(current_predictions) > 0:\n",
    "        # Plot smoothed lines (using pre-calculated values)\n",
    "        if len(current_predictions) > 1:\n",
    "            ax1.plot(\n",
    "                current_predictions['timestamp'], \n",
    "                current_predictions['reference_smooth'],\n",
    "                color=config['tls_color'], \n",
    "                linewidth=config['line_width'], \n",
    "                alpha=0.9, \n",
    "                label='TLS',\n",
    "                solid_capstyle='round'\n",
    "            )\n",
    "            ax1.plot(\n",
    "                current_predictions['timestamp'], \n",
    "                current_predictions['predicted_smooth'],\n",
    "                color=config['anglecam_color'], \n",
    "                linewidth=config['line_width'], \n",
    "                alpha=0.9, \n",
    "                label='AngleCam',\n",
    "                solid_capstyle='round'\n",
    "            )\n",
    "        \n",
    "        # Plot scatter points\n",
    "        ax1.scatter(\n",
    "            current_predictions['timestamp'], \n",
    "            current_predictions['reference_mean_angle'],\n",
    "            color=config['tls_color'], \n",
    "            s=config['marker_size'], \n",
    "            alpha=config['alpha_scatter'], \n",
    "            zorder=3,\n",
    "            edgecolors='white',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        ax1.scatter(\n",
    "            current_predictions['timestamp'], \n",
    "            current_predictions['predicted_mean_angle'],\n",
    "            color=config['anglecam_color'], \n",
    "            s=config['marker_size'], \n",
    "            alpha=config['alpha_scatter'], \n",
    "            zorder=3,\n",
    "            edgecolors='white',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        # Add legend only if we have data\n",
    "        if len(current_predictions) >= 1:\n",
    "            ax1.legend(fontsize=config['legend_fontsize'], frameon=False, loc='upper left')\n",
    "    \n",
    "    # Set fixed axis limits (pre-calculated for consistency)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    ax1.set_xlim(time_min, time_max)\n",
    "    \n",
    "    # Add current time indicator\n",
    "    ax1.axvline(current_dt, color='red', linestyle='--', alpha=0.8, linewidth=2, zorder=4)\n",
    "    \n",
    "    # Formatting\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "    ax1.xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18]))\n",
    "    ax1.grid(True, alpha=config['alpha_grid'])\n",
    "    ax1.spines[\"top\"].set_visible(False)\n",
    "    ax1.spines[\"right\"].set_visible(False)\n",
    "    ax1.set_xlabel(\"Time of Day\", fontsize=config['xlabel_fontsize'])\n",
    "    ax1.set_ylabel(\"Leaf Angle (Â°)\", fontsize=config['ylabel_fontsize'])\n",
    "    ax1.tick_params(axis=\"both\", which=\"major\", labelsize=config['tick_labelsize'])\n",
    "    \n",
    "    # RIGHT PLOT: Current image\n",
    "    if current_image_path.exists():\n",
    "        img = mpimg.imread(current_image_path)\n",
    "        ax2.imshow(img)\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title(f'{current_dt.strftime(\"%d-%m-%Y %H:%M\")}', \n",
    "                     fontsize=config['title_fontsize'], pad=20)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, f'Image not found', ha='center', va='center', \n",
    "                transform=ax2.transAxes, fontsize=12)\n",
    "        ax2.set_xlim(0, 1)\n",
    "        ax2.set_ylim(0, 1)\n",
    "    \n",
    "    # Save optimized\n",
    "    plt.subplots_adjust(left=0.06, right=0.98, top=0.92, bottom=0.12, wspace=config['subplot_spacing'])\n",
    "    plt.savefig(output_path, dpi=config['dpi'], facecolor='white', edgecolor='none')\n",
    "    plt.close()\n",
    "    plt.ion()  # Turn interactive mode back on\n",
    "\n",
    "def create_timelapse_animation(plant_name, image_dir, prediction_results, output_dir):\n",
    "    \"\"\"Create complete time-lapse animation for a plant with multiprocessing.\"\"\"\n",
    "    \n",
    "    print(f\"Creating animation for {plant_name}...\")\n",
    "    \n",
    "    # Setup directories\n",
    "    frames_dir = Path(output_dir) / \"frames\"\n",
    "    video_dir = Path(output_dir) / \"video\"\n",
    "    frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "    video_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all images and predictions\n",
    "    image_files = get_all_image_files(image_dir)\n",
    "    prediction_data = prepare_prediction_data(prediction_results)\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images and {len(prediction_data)} predictions\")\n",
    "    \n",
    "    # Debug: Show time range of images and predictions\n",
    "    if image_files:\n",
    "        img_start = image_files[0][0]\n",
    "        img_end = image_files[-1][0]\n",
    "        print(f\"Images time range: {img_start.strftime('%d-%m-%Y %H:%M')} to {img_end.strftime('%d-%m-%Y %H:%M')}\")\n",
    "    \n",
    "    if len(prediction_data) > 0:\n",
    "        pred_start = prediction_data['timestamp'].min()\n",
    "        pred_end = prediction_data['timestamp'].max()\n",
    "        print(f\"Predictions time range: {pred_start.strftime('%d-%m-%Y %H:%M')} to {pred_end.strftime('%d-%m-%Y %H:%M')}\")\n",
    "    \n",
    "    # Calculate FPS to achieve target duration\n",
    "    fps = len(image_files) / ANIMATION_CONFIG['target_duration_seconds']\n",
    "    \n",
    "    print(f\"Using {fps:.2f} FPS for {ANIMATION_CONFIG['target_duration_seconds']}s video\")\n",
    "    print(f\"This will create a {len(image_files) / fps:.1f}s duration video\")\n",
    "    \n",
    "    # Pre-calculate axis ranges for consistency\n",
    "    time_min = prediction_data['timestamp'].min()\n",
    "    time_max = prediction_data['timestamp'].max()\n",
    "    y_min = min(prediction_data['predicted_mean_angle'].min(), \n",
    "               prediction_data['reference_mean_angle'].min())\n",
    "    y_max = max(prediction_data['predicted_mean_angle'].max(), \n",
    "               prediction_data['reference_mean_angle'].max())\n",
    "    y_margin = 0.1 * (y_max - y_min)\n",
    "    time_range = (time_min, time_max)\n",
    "    y_range = (y_min - y_margin, y_max + y_margin)\n",
    "    \n",
    "    # Prepare arguments for multiprocessing\n",
    "    frame_args = []\n",
    "    for i, _ in enumerate(image_files):\n",
    "        frame_path = frames_dir / f\"frame_{i:06d}.png\"\n",
    "        args = (i, image_files, prediction_data, frame_path, ANIMATION_CONFIG, \n",
    "               plant_name, time_range, y_range)\n",
    "        frame_args.append(args)\n",
    "    \n",
    "    # Generate frames using multiprocessing\n",
    "    print(\"Generating frames with multiprocessing...\")\n",
    "    num_processes = min(mp.cpu_count() - 1, 30)  # Leave one core free, max 8 processes\n",
    "    \n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        list(tqdm(\n",
    "            pool.imap(create_animation_frame_optimized, frame_args),\n",
    "            total=len(frame_args),\n",
    "            desc=f\"Generating frames ({num_processes} processes)\"\n",
    "        ))\n",
    "    \n",
    "    # Create video\n",
    "    video_path = video_dir / f\"{plant_name}_timelapse.mp4\"\n",
    "    print(f\"Creating video: {video_path}\")\n",
    "    \n",
    "    # Get frame paths\n",
    "    frame_paths = [frames_dir / f\"frame_{i:06d}.png\" for i in range(len(image_files))]\n",
    "    \n",
    "    # Read first frame to get dimensions\n",
    "    first_frame = cv2.imread(str(frame_paths[0]))\n",
    "    height, width, layers = first_frame.shape\n",
    "    \n",
    "    # Create video writer with optimized codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(\n",
    "        str(video_path), fourcc, fps, (width, height)\n",
    "    )\n",
    "    \n",
    "    # Write frames to video\n",
    "    for frame_path in tqdm(frame_paths, desc=\"Writing video\"):\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        video_writer.write(frame)\n",
    "    \n",
    "    video_writer.release()\n",
    "    \n",
    "    # Try to close OpenCV windows (fails in headless environments, but that's OK)\n",
    "    try:\n",
    "        cv2.destroyAllWindows()\n",
    "    except:\n",
    "        pass  # Ignore errors in headless environments\n",
    "    \n",
    "    actual_duration = len(image_files) / fps\n",
    "    print(f\"Video saved: {video_path}\")\n",
    "    print(f\"Actual duration: {actual_duration:.1f}s at {fps} FPS\")\n",
    "    \n",
    "    # Create GIF\n",
    "    gif_path = video_dir / f\"{plant_name}_timelapse.gif\"\n",
    "    print(f\"Creating GIF: {gif_path}\")\n",
    "    \n",
    "    # Calculate GIF frame duration to match target duration\n",
    "    gif_frame_duration_ms = int((ANIMATION_CONFIG['target_duration_seconds'] * 1000) / len(image_files))\n",
    "    print(f\"GIF frame duration: {gif_frame_duration_ms}ms (target: {ANIMATION_CONFIG['target_duration_seconds']}s)\")\n",
    "    \n",
    "    # Test if consecutive frames are different\n",
    "    if len(frame_paths) >= 2:\n",
    "        img1 = imageio.imread(frame_paths[0])\n",
    "        img2 = imageio.imread(frame_paths[1])\n",
    "        print(f\"Frame 0 shape: {img1.shape}, Frame 1 shape: {img2.shape}\")\n",
    "        diff = np.mean(np.abs(img1.astype(float) - img2.astype(float)))\n",
    "        print(f\"Average pixel difference between first two frames: {diff:.2f}\")\n",
    "    \n",
    "    # Create GIF with imageio (more reliable than PIL)\n",
    "    print(\"Creating GIF with imageio...\")\n",
    "    \n",
    "    # Take every nth frame to reduce GIF size if needed\n",
    "    step = max(1, len(frame_paths) // 100)  # Limit to ~100 frames for reasonable file size\n",
    "    selected_paths = frame_paths[::step]\n",
    "    print(f\"Using every {step} frame(s), total: {len(selected_paths)} frames for GIF\")\n",
    "    \n",
    "    # Calculate duration for imageio (in seconds per frame)\n",
    "    gif_duration_per_frame = ANIMATION_CONFIG['target_duration_seconds'] / len(selected_paths)\n",
    "    print(f\"GIF duration per frame: {gif_duration_per_frame:.3f}s\")\n",
    "    \n",
    "    with imageio.get_writer(gif_path, mode='I', duration=gif_duration_per_frame) as writer:\n",
    "        for frame_path in tqdm(selected_paths, desc=\"Writing GIF frames\"):\n",
    "            if frame_path.exists():\n",
    "                image = imageio.imread(frame_path)\n",
    "                writer.append_data(image)\n",
    "    \n",
    "    # Verify GIF was created and get file size\n",
    "    if gif_path.exists():\n",
    "        gif_size_mb = gif_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"GIF saved: {gif_path}\")\n",
    "        print(f\"GIF size: {gif_size_mb:.1f} MB\")\n",
    "        print(f\"Total frames in GIF: {len(selected_paths)}\")\n",
    "        print(f\"Total animation duration: {gif_duration_per_frame * len(selected_paths):.1f}s\")\n",
    "    else:\n",
    "        print(\"ERROR: GIF file was not created!\")\n",
    "    \n",
    "    print(f\"Frames saved in: {frames_dir}\")\n",
    "    \n",
    "    return video_path, gif_path, frames_dir\n",
    "\n",
    "# Create animations for both plants\n",
    "CALATHEA_ANIMATION_OUTPUT_DIR = ANIMATION_OUTPUT_DIR / \"calathea\"\n",
    "MARANTA_ANIMATION_OUTPUT_DIR = ANIMATION_OUTPUT_DIR / \"maranta\"\n",
    "\n",
    "# Create Calathea animation\n",
    "calathea_video_path, calathea_gif_path, calathea_frames_dir = create_timelapse_animation(\n",
    "    \"calathea\", \n",
    "    TESTING_DIR_CALATHEA, \n",
    "    calathea_results, \n",
    "    CALATHEA_ANIMATION_OUTPUT_DIR\n",
    ")\n",
    "\n",
    "# Create Maranta animation\n",
    "maranta_video_path, maranta_gif_path, maranta_frames_dir = create_timelapse_animation(\n",
    "    \"maranta\", \n",
    "    TESTING_DIR_MARANTA, \n",
    "    maranta_results, \n",
    "    MARANTA_ANIMATION_OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(\"\\nAnimation creation complete!\")\n",
    "print(f\"Maranta MP4: {maranta_video_path}\")\n",
    "print(f\"Maranta GIF: {maranta_gif_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anglecam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
